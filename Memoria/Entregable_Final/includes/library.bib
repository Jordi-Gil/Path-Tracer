Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Cassagnabere2004,
author = {Cassagnab{\`{e}}re, Christophe and Rousselle, Fran{\c{c}}ois and Renaud, Christophe},
booktitle = {Proceedings GRAPHITE 2004 - 2nd International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia},
isbn = {1581138849},
keywords = {AR350,Global illumination,Hardware implementation,Path tracing,RenderMan},
title = {{Path tracing using the AR350 processor}},
year = {2004}
}
@inproceedings{Karras2013,
abstract = {We propose a new massively parallel algorithm for constructing high-quality bounding volume hierarchies (BVHs) for ray tracing. The algorithm is based on modifying an existing BVH to improve its quality, and executes in linear time at a rate of almost 40M tri- angles/sec on NVIDIA GTX Titan. We also propose an improved approach for parallel splitting of triangles prior to tree construc- tion. Averaged over 20 test scenes, the resulting trees offer over 90{\%} of the ray tracing performance of the best offline construction method (SBVH), while previous fast GPU algorithms offer only about 50{\%}. Compared to state-of-the-art, our method offers a sig- nificant improvement in the majority of practical workloads that need to construct the BVH for each frame. On the average, it gives the best overall performance when tracing between 7 million and 60 billion rays per frame. This covers most interactive applications, product and architectural design, and even movie rendering.},
author = {Karras, Tero and Aila, Timo},
booktitle = {Proceedings - High-Performance Graphics 2013, HPG 2013},
isbn = {9781450321358},
keywords = {Bounding volume hierarchies,Ray tracing},
title = {{Fast parallel construction of high-quality bounding volume hierarchies}},
year = {2013}
}
@article{Whitted1980,
abstract = {To accurately render a two-dimensional image of a three-dimensional scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of "rays" extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. A visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction, as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.},
author = {Whitted, Turner},
doi = {10.1145/358876.358882},
issn = {15577317},
journal = {Communications of the ACM},
keywords = {computer animation,computer graphics,raster displays,shading,visible surface algorithms},
title = {{An Improved Illumination Model for Shaded Display}},
year = {1980}
}
@book{ShirleyRTB,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing{\_} the Rest of Your Life.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {53},
publisher = {Peter Shirley},
title = {{Ray Tracing: The Rest of Your Life}},
url = {https://github.com/RayTracing/TheRestOfYourLife},
year = {2019}
}
@inproceedings{Fang2011,
abstract = {This paper presents a comprehensive performance comparison between CUDA and OpenCL. We have selected 16 benchmarks ranging from synthetic applications to real-world ones. We make an extensive analysis of the performance gaps taking into account programming models, optimization strategies, architectural details, and underlying compilers. Our results show that, for most applications, CUDA performs at most 30{\%} better than OpenCL. We also show that this difference is due to unfair comparisons: in fact, OpenCL can achieve similar performance to CUDA under a fair comparison. Therefore, we define a fair comparison of the two types of applications, providing guidelines for more potential analyses. We also investigate OpenCL's portability by running the benchmarks on other prevailing platforms with minor modifications. Overall, we conclude that OpenCL's portability does not fundamentally affect its performance, and OpenCL can be a good alternative to CUDA. ? 2011 IEEE.},
author = {Fang, Jianbin and Varbanescu, Ana Lucia and Sips, Henk},
booktitle = {Proceedings of the International Conference on Parallel Processing},
doi = {10.1109/ICPP.2011.45},
isbn = {9780769545103},
issn = {01903918},
keywords = {CUDA,OpenCL,Performance Comparison},
title = {{A comprehensive performance comparison of CUDA and OpenCL}},
year = {2011}
}
@article{Phong1975,
abstract = {The quality of computer generated images of three-dimensional scenes$\backslash$ndepends on the shading technique used to paint the objects on the$\backslash$ncathode-ray tube screen. The shading algorithm itself depends in$\backslash$npart on the method for modeling the object, which also determines$\backslash$nthe hidden surface algorithm. The various methods of object modeling,$\backslash$nshading, and hidden surface removal are thus strongly interconnected.$\backslash$nSeveral shading techniques corresponding to different methods of$\backslash$nobject modeling and the related hidden surface algorithms are presented$\backslash$nhere. Human visual perception and the fundamental laws of optics$\backslash$nare considered in the development of a shading rule that provides$\backslash$nbetter quality and increased realism in generated images.},
author = {Phong, Bui Tuong},
doi = {10.1145/360825.360839},
issn = {15577317},
journal = {Communications of the ACM},
keywords = {computer graphics,graphic display,hidden surface removal,shading},
number = {6},
pages = {311----317},
title = {{Illumination for Computer Generated Pictures}},
volume = {18},
year = {1975}
}
@inproceedings{Karras2012,
abstract = {A number of methods for constructing bounding volume hierarchies and point-based octrees on the GPU are based on the idea of ordering primitives along a space-filling curve. A major shortcoming with these methods is that they construct levels of the tree sequentially, which limits the amount of parallelism that they can achieve. We present a novel approach that improves scalability by constructing the entire tree in parallel. Our main contribution is an in-place algorithm for constructing binary radix trees, which we use as a building block for other types of trees.},
author = {Karras, Tero},
booktitle = {High-Performance Graphics 2012, HPG 2012 - ACM SIGGRAPH / Eurographics Symposium Proceedings},
doi = {10.2312/EGGH/HPG12/033-037},
isbn = {9783905674415},
title = {{Maximizing parallelism in the construction of bvhs, octrees, and k-d trees}},
year = {2012}
}
@article{Karimi2010,
abstract = {CUDA and OpenCL are two different frameworks for GPU programming. OpenCL is an open standard that can be used to program CPUs, GPUs, and other devices from different vendors, while CUDA is specific to NVIDIA GPUs. Although OpenCL promises a portable language for GPU programming, its generality may entail a performance penalty. In this paper, we use complex, near-identical kernels from a Quantum Monte Carlo application to compare the performance of CUDA and OpenCL. We show that when using NVIDIA compiler tools, converting a CUDA kernel to an OpenCL kernel involves minimal modifications. Making such a kernel compile with ATI's build tools involves more modifications. Our performance tests measure and compare data transfer times to and from the GPU, kernel execution times, and end-to-end application execution times for both CUDA and OpenCL.},
archivePrefix = {arXiv},
arxivId = {1005.2581},
author = {Karimi, Kamran and Dickson, Neil G. and Hamze, Firas},
eprint = {1005.2581},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/cuda-ocl-kdh.pdf:pdf},
journal = {Computing Research Repository - CORR},
number = {1},
pages = {10},
title = {{A Performance Comparison of CUDA and OpenCL}},
url = {http://arxiv.org/abs/1005.2581},
volume = {abs/1005.2},
year = {2010}
}
@article{Christensen2018,
abstract = {Pixar's RenderMan renderer is used to render all of Pixar's films and by many film studios to render visual effects for live-action movies. RenderMan started as a scanline renderer based on the Reyes algorithm, and it was extended over the years with ray tracing and several global illumination algorithms. This article describes the modern version of RenderMan, a new architecture for an extensible and programmable path tracer with many features that are essential to handle the fiercely complex scenes in movie production. Users can write their own materials using a bxdf interface and their own light transport algorithms using an integrator interfaceâ€”or they can use the materials and light transport algorithms provided with RenderMan. Complex geometry and textures are handled with efficient multi-resolution representations, with resolution chosen using path differentials. We trace rays and shade ray hit points in medium-sized groups, which provides the benefits of SIMD execution without excessive memory overhead or data streaming. The path-tracing architecture handles surface, subsurface, and volume scattering. We show examples of the use of path tracing, bidirectional path tracing, VCM, and UPBP light transport algorithms. We also describe our progressive rendering for interactive use and our adaptation of denoising techniques.},
author = {Christensen, Per and Fong, Julian and Shade, Jonathan and Wooten, Wayne and Schubert, Brenden and Kensler, Andrew and Friedman, Stephen and Kilpatrick, Charlie and Ramshaw, Cliff and Bannister, Marc and Rayner, Brenton and Brouillat, Jonathan and Liani, Max},
doi = {10.1145/3182162},
issn = {15577368},
journal = {ACM Transactions on Graphics},
keywords = {Complex scenes,Computergenerated images,Global illumination,Path tracing,Pixar,Production rendering,Ray tracing,RenderMan,Visual effects},
title = {{RenderMan: An advanced path-tracing architecture for movie rendering}},
year = {2018}
}
@inproceedings{Appel1968,
abstract = {Some applications of computer graphics require a vivid illusion of reality. These include the spatial organization of machine parts, conceptual architectural design, simulation of mechanisms, and industrial design. There has been moderate success in the automatic generation of wire frame, cardboard model, polyhedra, and quadric surface line drawings. The capability of the machine to generate vivid sterographic pictures has been demonstrated. There are, however considerable reasons for developing techniques by which line drawings of solids can be shaded, especially the enhancement of the sense of solidity and depth. Figures 1 and 2 illustrate the value of shading and shadow casting in spatial description. In the line drawing there is no clue as to the relative position of the flat plane and the sheet metal console. When shadows are rendered, it is clear that the plane is below and to the rear of the console, and the hollow nature of the sheet metal assembly is emphasized. Shading can specify the tone or color of a surface and the amount of light falling upon that surface from one or more light sources. Shadows when sharply defined tend to suggest another viewpoint and improves surface definition. When controlled, shading can also emphasize particular parts of the drawing. If techniques for the automatic determination of chiaroscuro with good resolution should prove to be competitive with line drawings, and this is a possibility, machine generated photographs might replace line drawings as the principal mode of graphical communication in engineering and architecture.},
author = {Appel, Arthur},
booktitle = {AFIPS Spring Joint Computing Conference},
doi = {10.1145/1468075.1468082},
title = {{Some techniques for shading machine renderings of solids}},
year = {1968}
}
@inproceedings{Rubin1980,
abstract = {Hierarchical representations of 3-dimensional objects are both time and space efficient. They typically consist of trees whose branches represent bounding volumes and whose terminal nodes represent primitive object elements (usually polygons). This paper describes a method whereby the object space is represented entirely by a hierarchical data structure consisting of bounding volumes, with no other form of representation. This homogencity allows the visible surface rendering to be performed simply and efficiently. The bounding volumes selected for this algorithm are parallelepipeds oriented to minimize their size. With this representation, any surface can be rendered since in the limit the bounding volumes make up a point representation of the object. The advantage is that the visibility calculations consist only of a search through the data structure to determine the correspondence between terminal level bounding volumes and the current pixel. For ray tracing algorithms, this means that a simplified operation will produce the point of intersection of each ray with the bounding volumes. Memory requirements are minimized by expanding or fetching the lower levels of the hierarchy only when required. Because the viewing process has a single operation and primitive type, the software or hardware chosen to implement the search can be highly optimized for very fast execution.},
author = {Rubin, Steven M. and Whitted, Turner},
booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1980},
doi = {10.1145/800250.807479},
isbn = {0897910214},
keywords = {Computer graphics,Hierarchical data structures,Object descriptions,Visible surface algorithms},
title = {{A 3-dimensional representation for fast rendering of complex scenes}},
year = {1980}
}
@inproceedings{Hunt2008,
abstract = {The key to efficient ray tracing is the use of effective acceleration data structures. Traditionally, acceleration structures have been constructed under the assumption that rays approach from any direction with equal probability. However, we observe that for any particular frame the system has significant knowledge about the rays, especially eye rays and hard/soft shadow rays. In this paper we demonstrate that by using this information in conjunction with an appropriate acceleration structure - a set of one or more perspective grids - that ray tracing performance can be significantly improved over prior approaches. This acceleration structure can easily be rebuilt per frame, and provides significantly improved performance for rays originating at or near particular points such as the eye point and the light source(s), without sacrificing the ability to trace arbitrary rays. We demonstrate true real-time frame rates on a game-like scene rendered on an eight-core desktop PC at 1920times1200 resolution for primary visibility, and hard shadows, along with lower frame rates for Monte Carlo soft shadows. In particular, we demonstrate the fastest hard shadow ray-tracing results that we are aware of. We argue that the perspective grid acceleration structure provides insight into why the Z buffer algorithm is faster than traditional ray tracing and shows there is a useful continuum of visibility algorithms between the two traditional approaches.},
author = {Hunt, Warren and Mark, William R.},
booktitle = {RT'08 - IEEE/EG Symposium on Interactive Ray Tracing 2008, Proceedings},
doi = {10.1109/RT.2008.4634613},
isbn = {9781424427413},
keywords = {I.3.7 [computing methodologies]: computer graphics},
pages = {3--10},
title = {{Ray-specialized acceleration structures for ray tracing}},
year = {2008}
}
@incollection{Jensen1996,
abstract = {This paper presents a two pass global illumination method based on the concept of photon maps. It represents a significant improvement of a previously described approach both with respect to speed, accuracy and versatility. In the first pass two photon maps are created by emitting packets of energy (photons) from the light sources and storing these as they hit surfaces within the scene. We use one high resolution caustics photon map to render caustics that are visualized directly and one low resolution photon map that is used during the rendering step. The scene is rendered using a distribution ray tracing algorithm optimized by using the in- formation in the photon maps. Shadow photons are used to render shadows more efficiently and the directional information in the photon map is used to generate optimized sampling directions and to limit the recursion in the distribution ray tracer by providing an estimate of the radiance on all surfaces with the exception of specular and highly glossy surfaces. The results presented demonstrate global illumination in scenes containing pro- cedural objects and surfaces with diffuse and glossy reflection models. The imple- mentation is also compared with the Radiance program.},
author = {Jensen, Henrik Wann},
booktitle = {Rendering Techniques '96},
doi = {10.1007/978-3-7091-7484-5_3},
pages = {21--30},
publisher = {Springer Vienna},
title = {{Global Illumination using Photon Maps}},
year = {1996}
}
@inproceedings{Blinn1977,
abstract = {In the production of computer generated pictures of three dimensional objects, one stage of the calculation is the determination of the intensity of a given object once its visibility has been established. This is typically done by modelling the surface as a perfect diffuser, sometimes with a specular component added for the simulation of hilights. This paper presents a more accurate function for the generation of hilights which is based on some experimental measurements of how light reflects from real surfaces. It differs from previous models in that the intensity of the hilight changes with the direction of the light source. Also the position and shape of the hilights is somewhat different from that generated by simpler models. Finally, the hilight function generates different results when simulating metallic vs. nonmetallic surfaces. Many of the effects so generated are somewhat subtle and are apparent only during movie sequences. Some representative still frames from such movies are included.},
author = {Blinn, James F.},
booktitle = {Proceedings of the 4th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1977},
doi = {10.1145/563858.563893},
keywords = {Computer graphics,Graphic display,Hidden surface removal.,Shading},
title = {{Models of light reflection for computer synthesized pictures}},
year = {1977}
}
@inproceedings{Immel1986,
abstract = {A general radiosity method accounting for all interreflections of light between diffuse and non-diffuse surfaces in complex environments is introduced. As contrasted with previous radiosity methods, surfaces are no longer required to be perfectly diffuse reflectors and emitters. A complete, viewer independent description of the light leaving each surface in each direction is computed, allowing dynamic sequences of images to be rendered with little additional computation per image. Phenomena such as 'reflection tracking', reflections following a moving observer across a specular surface are produced. Secondary light sources, such as the light from a spotlight reflecting off a mirror onto a wall are also accounted for.},
author = {Immel, David S. and Cohen, Michael F. and Greenberg, Donald P.},
booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1986},
doi = {10.1145/15922.15901},
isbn = {0897911962},
keywords = {Bi-directional reflectance,Depth buffer,Hidden-surface,Intensity,Non-diffuse reflection,Radiosity},
title = {{A radiosity method for non-diffuse environments}},
year = {1986}
}
@article{Lotto1999,
abstract = {If Mach bands arise as an empirical consequence of real-world luminance profiles, several predictions follow. First, the appearance of Mach bands should accord with the appearance of naturally occurring highlights and lowlights. Second, altering the slope of an ambiguous luminance gradient so that it corresponds more closely to gradients that are typically adorned with luminance maxima and minima in the position of Mach bands should enhance the illusion. Third, altering a luminance gradient so that it corresponds more closely to gradients that normally lack luminance maxima and minima in the position of Mach bands should diminish the salience of the illusion. Fourth, the perception of Mach bands elicited by the same luminance gradient should be changed by contextual cues that indicate whether the gradient is more or less likely to signify a curved or a flat surface. Because each of these predictions is met, we conclude that Mach bands arise because the association elicited by the stimulus (the percept) incorporates these features as a result of past experience.},
author = {Lotto, R. Beau and Williams, S. Mark and Purves, Dale},
doi = {10.1073/pnas.96.9.5245},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
title = {{Mach bands as empirically derived associations}},
year = {1999}
}
@book{ShirleyRTC,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing{\_} The Next Week.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {50},
publisher = {Peter Shirley},
title = {{Ray Tracing : The Next Week}},
url = {https://github.com/petershirley/raytracingthenextweek},
year = {2019}
}
@book{ShirleyRTA,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing in a Weekend.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {41},
publisher = {Peter Shirley},
title = {{Ray Tracing in One Weekend}},
url = {https://github.com/RayTracing/InOneWeekend},
year = {2019}
}
@inproceedings{Kajiya1986,
abstract = {We present an integral equation which generallzes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting renderlng algorithm extends the range of optical phenomena which can be effectively simulated. KEYWORDS: computer graphics, raster graphics{\~{}} ray tracing{\~{}} radios-ity{\~{}} monte carlo, distributed ray tracing, variance reduction. CR CATEGORIES: 1.3.3, 1.3.5, 1.3.7 1. T h e r e n d e r i n g e q u a t i o n The technique we present subsumes a wide variety of rendering algo-rithms and provides a unified context for viewing them as more or less accurate approximations to the solution of a single equation. That this should be so is not surprising once it is realized that all rendering methods attempt to model the same physical phenomenon, that of light scattering off various types of surfaces. We mention that the idea behind the rendering equation is hardly new. A description of the phenomenon simulated by this equation has been well studied in the radiative heat transfer literature for years [Siegel and Howell 1981]. However, the form in which we present this equation is well suited for computer graphics, and we believe that this form has not appeared before.},
author = {Kajiya, James T.},
booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1986},
doi = {10.1145/15922.15902},
isbn = {0897911962},
keywords = {Computer graphics,Distributed ray tracing,Monte Carlo,Radiosity,Raster graphics,Ray tracing,Variance reduction},
title = {{The rendering equation}},
year = {1986}
}
@article{Lafortune1993,
abstract = {In this paper we present a new Monte Carlo rendering algorithm that seamlessly integrates the ideas of},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lafortune, Eric P. and Willems, Yves D.},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
isbn = {3-211-82883-4},
issn = {1098-6596},
journal = {Proc. SIGGRAPH},
keywords = {illumination and photorealistic render-,rendering and visualisation global},
pmid = {25246403},
title = {{Bi-Directional Path Tracing}},
year = {1993}
}
@inproceedings{Veach1997,
abstract = {We present a new Monte Carlo method for solving the light transport problem, inspired by theMetropolis sampling method in computational physics. To render an image, we generate a sequence of light transport paths by randomly mutating a single current path (e.g. adding a new vertex to the path). Eachmutation is accepted or rejected with a care- fully chosen probability, to ensure that paths are sampled according to the contribution they make to the ideal image. We then estimate this image by sampling many paths, and recording their locations on the image plane. Our algorithm is unbiased, handles general geometric and scattering models, uses little storage, and can be orders of magnitude more efficient than previous unbiased approaches. It performs especially well on problems that are usually con- sidered difficult, e.g. those involving bright indirect light, small geometric holes, or glossy surfaces. Furthermore, it is competitive with previous unbiased algorithms even for relatively simple scenes. The key advantage of the Metropolis approach is that the path space is explored locally, by favoring mutations that make small changes to the current path. This has several consequences. First, the average cost per sample is small (typically only one or two rays). Second, once an impor- tant path is found, the nearby paths are explored as well, thus amortizing the expense of finding such paths over many samples. Third, themutation set is easily extended. By con- structing mutations that preserve certain properties of the path (e.g. which light source is used) while changing others, we can exploit various kinds of coherence in the scene. It is often possible to handle difficult lighting problems efficiently by designing a specialized mutation in this way. CR},
author = {Veach, Eric and Guibas, Leonidas J.},
booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1997},
doi = {10.1145/258734.258775},
isbn = {0897918967},
keywords = {Markov Chain Monte Carlo methods,Metropolis-Hastings algorithm,Monte Carlo integration,global illumination,lighting simulation,physically-based rendering,radiative heat transfer,variance reduction},
title = {{Metropolis light transport}},
year = {1997}
}
@article{Henri1971,
abstract = {A procedure for computing shaded pictures of curved surfaces is presented. The surface is approximated by small polygons in order to solve easily the hidden-parts problem, but the shading of each polygon is computed so that discontinuities of shade are eliminated across the surface and a smooth appearance is obtained. In order to achieve speed efficiency, the technique developed by Watkins is used which makes possible a hardware implementation of this algorithm.},
author = {Henri, Gouraud},
doi = {10.1109/T-C.1971.223313},
issn = {00189340},
journal = {IEEE Transactions on Computers},
keywords = {Coons patches,curved surfaces,halftone,hidden-,line removal,shading},
title = {{Continuous Shading of Curved Surfaces}},
year = {1971}
}
