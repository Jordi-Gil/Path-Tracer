Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Henri1971,
abstract = {A procedure for computing shaded pictures of curved surfaces is presented. The surface is approximated by small polygons in order to solve easily the hidden-parts problem, but the shading of each polygon is computed so that discontinuities of shade are eliminated across the surface and a smooth appearance is obtained. In order to achieve speed efficiency, the technique developed by Watkins is used which makes possible a hardware implementation of this algorithm.},
author = {Henri, Gouraud},
journal = {IEEE Transactions on Computers},
keywords = {Coons patches,curved surfaces,halftone,hidden-,line removal,shading},
pages = {623 ---- 629},
title = {{Continuous Shading of Curved Surfaces}},
year = {1971}
}
@book{ShirleyRTA,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing in a Weekend.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {41},
publisher = {Peter Shirley},
title = {{Ray Tracing in One Weekend}},
url = {https://github.com/RayTracing/InOneWeekend},
year = {2019}
}
@article{Christensen2018,
abstract = {Pixar's RenderMan renderer is used to render all of Pixar's films and by many film studios to render visual effects for live-action movies. RenderMan started as a scanline renderer based on the Reyes algorithm, and it was extended over the years with ray tracing and several global illumination algorithms. This article describes the modern version of RenderMan, a new architecture for an extensible and programmable path tracer with many features that are essential to handle the fiercely complex scenes in movie production. Users can write their own materials using a bxdf interface and their own light transport algorithms using an integrator interface—or they can use the materials and light transport algorithms provided with RenderMan. Complex geometry and textures are handled with efficient multi-resolution representations, with resolution chosen using path differentials. We trace rays and shade ray hit points in medium-sized groups, which provides the benefits of SIMD execution without excessive memory overhead or data streaming. The path-tracing architecture handles surface, subsurface, and volume scattering. We show examples of the use of path tracing, bidirectional path tracing, VCM, and UPBP light transport algorithms. We also describe our progressive rendering for interactive use and our adaptation of denoising techniques.},
author = {Christensen, Per and Fong, Julian and Shade, Jonathan and Wooten, Wayne and Schubert, Brenden and Kensler, Andrew and Friedman, Stephen and Kilpatrick, Charlie and Ramshaw, Cliff and Bannister, Marc and Rayner, Brenton and Brouillat, Jonathan and Liani, Max},
journal = {ACM Transactions on Graphics},
keywords = {Complex scenes,Computergenerated images,Global illumination,Path tracing,Pixar,Production rendering,Ray tracing,RenderMan,Visual effects},
title = {{RenderMan: An advanced path-tracing architecture for movie rendering}},
year = {2018}
}
@inproceedings{Veach1997,
abstract = {We present a new Monte Carlo method for solving the light transport problem, inspired by theMetropolis sampling method in computational physics. To render an image, we generate a sequence of light transport paths by randomly mutating a single current path (e.g. adding a new vertex to the path). Eachmutation is accepted or rejected with a care- fully chosen probability, to ensure that paths are sampled according to the contribution they make to the ideal image. We then estimate this image by sampling many paths, and recording their locations on the image plane. Our algorithm is unbiased, handles general geometric and scattering models, uses little storage, and can be orders of magnitude more efficient than previous unbiased approaches. It performs especially well on problems that are usually con- sidered difficult, e.g. those involving bright indirect light, small geometric holes, or glossy surfaces. Furthermore, it is competitive with previous unbiased algorithms even for relatively simple scenes. The key advantage of the Metropolis approach is that the path space is explored locally, by favoring mutations that make small changes to the current path. This has several consequences. First, the average cost per sample is small (typically only one or two rays). Second, once an impor- tant path is found, the nearby paths are explored as well, thus amortizing the expense of finding such paths over many samples. Third, themutation set is easily extended. By con- structing mutations that preserve certain properties of the path (e.g. which light source is used) while changing others, we can exploit various kinds of coherence in the scene. It is often possible to handle difficult lighting problems efficiently by designing a specialized mutation in this way. CR},
author = {Veach, Eric and Guibas, Leonidas J.},
booktitle = {Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1997},
keywords = {Markov Chain Monte Carlo methods,Metropolis-Hastings algorithm,Monte Carlo integration,global illumination,lighting simulation,physically-based rendering,radiative heat transfer,variance reduction},
pages = {65----76},
title = {{Metropolis light transport}},
year = {1997}
}
@article{Schlick1994,
abstract = {A new BRDF model is presented which can be viewed as an kind of intermediary model between empirism and theory. Main results of physics are observed (energy conservation, reciprocity rule, microfacet theory) and numerous phenomena involved in light reflection are accounted for, in a physically plausible way (incoherent and coherent reflection, spectrum modifications, anisotropy, self‐shadowing, multiple surface and subsurface reflection, differences between homogeneous and heterogeneous materials). The model has been especially intended for computer graphics applications and therefore includes two main features: simplicity (a small number of intuitively understandable parameters controls the model) and efficiency (the formulation provides adequation to Monte‐Carlo rendering techniques and/or hardware implementations). {\textcopyright} 1994 Eurographics Association},
author = {Schlick, Christophe},
journal = {Computer Graphics Forum},
keywords = {Bidirectional Reflectance Distribution Function,Optimization,Physically‐Based Rendering},
title = {{An Inexpensive BRDF Model for Physically‐based Rendering}},
year = {1994}
}
@article{Lotto1999,
abstract = {If Mach bands arise as an empirical consequence of real-world luminance profiles, several predictions follow. First, the appearance of Mach bands should accord with the appearance of naturally occurring highlights and lowlights. Second, altering the slope of an ambiguous luminance gradient so that it corresponds more closely to gradients that are typically adorned with luminance maxima and minima in the position of Mach bands should enhance the illusion. Third, altering a luminance gradient so that it corresponds more closely to gradients that normally lack luminance maxima and minima in the position of Mach bands should diminish the salience of the illusion. Fourth, the perception of Mach bands elicited by the same luminance gradient should be changed by contextual cues that indicate whether the gradient is more or less likely to signify a curved or a flat surface. Because each of these predictions is met, we conclude that Mach bands arise because the association elicited by the stimulus (the percept) incorporates these features as a result of past experience.},
author = {Lotto, R. Beau and Williams, S. Mark and Purves, Dale},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
pages = {5245 ---- 5250},
title = {{Mach bands as empirically derived associations}},
year = {1999}
}
@article{Kurt2010,
abstract = {M the editor: The graphic representation of the formulas integral to this paper are poorly interpreted due the e-quarterly's restricted access to use loaded java scripts. Please use this link to download a supplemented PDF version of the article.},
author = {Kurt, Murat and Szirmay-Kalos, L{\'{a}}szl{\'{o}} and Křiv{\'{a}}nek, Jaroslav},
journal = {ACM SIGGRAPH Computer Graphics},
title = {{An anisotropic BRDF model for fitting and Monte Carlo rendering}},
year = {2010}
}
@article{Whitted1980,
abstract = {To accurately render a two-dimensional image of a three-dimensional scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of "rays" extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. A visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction, as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.},
author = {Whitted, Turner},
journal = {Communications of the ACM},
keywords = {computer animation,computer graphics,raster displays,shading,visible surface algorithms},
pages = {343----349},
title = {{An Improved Illumination Model for Shaded Display}},
year = {1980}
}
@inproceedings{Immel1986,
abstract = {A general radiosity method accounting for all interreflections of light between diffuse and non-diffuse surfaces in complex environments is introduced. As contrasted with previous radiosity methods, surfaces are no longer required to be perfectly diffuse reflectors and emitters. A complete, viewer independent description of the light leaving each surface in each direction is computed, allowing dynamic sequences of images to be rendered with little additional computation per image. Phenomena such as 'reflection tracking', reflections following a moving observer across a specular surface are produced. Secondary light sources, such as the light from a spotlight reflecting off a mirror onto a wall are also accounted for.},
author = {Immel, David S. and Cohen, Michael F. and Greenberg, Donald P.},
booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1986},
keywords = {Bi-directional reflectance,Depth buffer,Hidden-surface,Intensity,Non-diffuse reflection,Radiosity},
pages = {133----142},
title = {{A radiosity method for non-diffuse environments}},
year = {1986}
}
@article{Nickolls2008,
abstract = {The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. Furthermore, their parallelism continues to scale with Moore's law. The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications transparently scale their parallelism to manycore GPUs with widely varying numbers of cores.},
author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
journal = {Queue},
month = {mar},
pages = {40--53},
title = {{Scalable parallel programming with CUDA}},
year = {2008}
}
@article{Samet1989,
abstract = {A ray tracing implementation is described that is based on an octree representation of a scene. Rays are traced through the scene by calculating the blocks through which they pass. This calculation is performed in a bottom-up manner through the use of neighbor finding. The octrees are assumed to be implemented by a pointer representation. {\textcopyright} 1989.},
author = {Samet, Hanan},
doi = {10.1016/0097-8493(89)90006-X},
issn = {00978493},
journal = {Computers and Graphics},
pages = {445----460},
title = {{Implementing ray tracing with octrees and neighbor finding}},
year = {1989}
}
@inproceedings{Kajiya1986,
abstract = {We present an integral equation which generallzes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting renderlng algorithm extends the range of optical phenomena which can be effectively simulated. KEYWORDS: computer graphics, raster graphics{\~{}} ray tracing{\~{}} radios-ity{\~{}} monte carlo, distributed ray tracing, variance reduction. CR CATEGORIES: 1.3.3, 1.3.5, 1.3.7 1. T h e r e n d e r i n g e q u a t i o n The technique we present subsumes a wide variety of rendering algo-rithms and provides a unified context for viewing them as more or less accurate approximations to the solution of a single equation. That this should be so is not surprising once it is realized that all rendering methods attempt to model the same physical phenomenon, that of light scattering off various types of surfaces. We mention that the idea behind the rendering equation is hardly new. A description of the phenomenon simulated by this equation has been well studied in the radiative heat transfer literature for years [Siegel and Howell 1981]. However, the form in which we present this equation is well suited for computer graphics, and we believe that this form has not appeared before.},
author = {Kajiya, James T.},
booktitle = {Proceedings of the 13th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1986},
keywords = {Computer graphics,Distributed ray tracing,Monte Carlo,Radiosity,Raster graphics,Ray tracing,Variance reduction},
pages = {143----150},
title = {{The rendering equation}},
year = {1986}
}
@book{ShirleyRTB,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing{\_} the Rest of Your Life.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {53},
publisher = {Peter Shirley},
title = {{Ray Tracing: The Rest of Your Life}},
url = {https://github.com/RayTracing/TheRestOfYourLife},
year = {2019}
}
@inproceedings{Appel1968,
abstract = {Some applications of computer graphics require a vivid illusion of reality. These include the spatial organization of machine parts, conceptual architectural design, simulation of mechanisms, and industrial design. There has been moderate success in the automatic generation of wire frame, cardboard model, polyhedra, and quadric surface line drawings. The capability of the machine to generate vivid sterographic pictures has been demonstrated. There are, however considerable reasons for developing techniques by which line drawings of solids can be shaded, especially the enhancement of the sense of solidity and depth. Figures 1 and 2 illustrate the value of shading and shadow casting in spatial description. In the line drawing there is no clue as to the relative position of the flat plane and the sheet metal console. When shadows are rendered, it is clear that the plane is below and to the rear of the console, and the hollow nature of the sheet metal assembly is emphasized. Shading can specify the tone or color of a surface and the amount of light falling upon that surface from one or more light sources. Shadows when sharply defined tend to suggest another viewpoint and improves surface definition. When controlled, shading can also emphasize particular parts of the drawing. If techniques for the automatic determination of chiaroscuro with good resolution should prove to be competitive with line drawings, and this is a possibility, machine generated photographs might replace line drawings as the principal mode of graphical communication in engineering and architecture.},
author = {Appel, Arthur},
booktitle = {AFIPS Spring Joint Computing Conference},
pages = {37--45},
title = {{Some techniques for shading machine renderings of solids}},
year = {1968}
}
@inproceedings{Rubin1980,
abstract = {Hierarchical representations of 3-dimensional objects are both time and space efficient. They typically consist of trees whose branches represent bounding volumes and whose terminal nodes represent primitive object elements (usually polygons). This paper describes a method whereby the object space is represented entirely by a hierarchical data structure consisting of bounding volumes, with no other form of representation. This homogencity allows the visible surface rendering to be performed simply and efficiently. The bounding volumes selected for this algorithm are parallelepipeds oriented to minimize their size. With this representation, any surface can be rendered since in the limit the bounding volumes make up a point representation of the object. The advantage is that the visibility calculations consist only of a search through the data structure to determine the correspondence between terminal level bounding volumes and the current pixel. For ray tracing algorithms, this means that a simplified operation will produce the point of intersection of each ray with the bounding volumes. Memory requirements are minimized by expanding or fetching the lower levels of the hierarchy only when required. Because the viewing process has a single operation and primitive type, the software or hardware chosen to implement the search can be highly optimized for very fast execution.},
author = {Rubin, Steven M. and Whitted, Turner},
booktitle = {Proceedings of the 7th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1980},
keywords = {Computer graphics,Hierarchical data structures,Object descriptions,Visible surface algorithms},
title = {{A 3-dimensional representation for fast rendering of complex scenes}},
year = {1980}
}
@techreport{DonaldMeagher1982,
abstract = {A geometric modeling technique called Octree Encoding is presented. Arbitrary 3-D objects can be represented to any specified resolution in a hierarchical I-ary tree structure or "octree." Objects may be concave or convex, have holes (including interior holes), consist of disjoint parts, and possess sculptured (i.e., "free-form") surfaces. The memory required for representation and manipulation is on the order of the surface area of the object. A complexity metric is proposed based on the number of nodes in an object's tree representation. Efficient (linear time) algorithms have been developed for the Boolean operations (union, intersection and difference), geometric operations (translation, scaling and rotation), N-dimensional interference detection, and display from any point in space with hidden surfaces removed. The algorithms require neither floating-point operations, integer multiplications, nor integer divisions. In addition, many independent sets of very simple calculations are typically generated, allowing implementation over many inexpensive high-bandwidth processors operating in parallel. Real time analysis and manipulation of highly complex situations thus becomes possible.},
author = {{Donald Meagher}},
booktitle = {COMPUTER GRAPHICS AND IMAGE PROCESSING},
title = {{Geometric Modeling Using Octree Encoding}},
year = {1982}
}
@article{Lauterbach2009,
abstract = {We present two novel parallel algorithms for rapidly constructing bounding volume hierarchies on manycore GPUs. The first uses a linear ordering derived from spatial Morton codes to build hierarchies extremely quickly and with high parallel scalability. The second is a top-down approach that uses the surface area heuristic (SAH) to build hierarchies optimized for fast ray tracing. Both algorithms are combined into a hybrid algorithm that removes existing bottlenecks in the algorithm for GPU construction performance and scalability leading to significantly decreased build time. The resulting hierarchies are close in to optimized SAH hierarchies, but the construction process is substantially faster, leading to a significant net benefit when both construction and traversal cost are accounted for. Our preliminary results show that current GPU architectures can compete with CPU implementations of hierarchy construction running on multicore systems. In practice, we can construct hierarchies of models with up to several million triangles and use them for fast ray tracing or other applications. {\textcopyright} 2008 The Eurographics Association and Blackwell Publishing Ltd.},
author = {Lauterbach, C. and Garland, M. and Sengupta, S. and Luebke, D. and Manocha, D.},
doi = {10.1111/j.1467-8659.2009.01377.x},
issn = {14678659},
journal = {Computer Graphics Forum},
pages = {375--384},
title = {{Fast BVH construction on GPUs}},
year = {2009}
}
@inproceedings{Karras2012,
abstract = {A number of methods for constructing bounding volume hierarchies and point-based octrees on the GPU are based on the idea of ordering primitives along a space-filling curve. A major shortcoming with these methods is that they construct levels of the tree sequentially, which limits the amount of parallelism that they can achieve. We present a novel approach that improves scalability by constructing the entire tree in parallel. Our main contribution is an in-place algorithm for constructing binary radix trees, which we use as a building block for other types of trees.},
author = {Karras, Tero},
booktitle = {High-Performance Graphics 2012, HPG 2012 - ACM SIGGRAPH / Eurographics Symposium Proceedings},
title = {{Maximizing parallelism in the construction of bvhs, octrees, and k-d trees}},
year = {2012}
}
@inproceedings{Gunther2007,
abstract = {Recent GPU ray tracers can already achieve performance competitive to that of their CPU counterparts. Nevertheless, these systems can not yet fully exploit the capabilities of modern GPUs and can only handle medium-sized, static scenes. In this paper we present a BVH-based GPU ray tracer with a parallel packet traversal algorithm using a shared stack. We also present a fast, CPU-based BVH construction algorithm which very accurately approximates the surface area heuristic using streamed binning while still being one order of magnitude faster than previously published results. Furthermore, using a BVH allows us to push the size limit of supported scenes on the GPU: We can now ray trace the 12.7 million triangle POWER PLANT at 1024×1024 image resolution with 3 fps, including shading and shadows. {\textcopyright} 2007 IEEE.},
author = {G{\"{u}}nther, Johannes and Popov, Stefan and Seidel, Hans Peter and Slusallek, Philipp},
booktitle = {IEEE/ EG Symposium on Interactive Ray Tracing 2007 Proceedings, IRT},
doi = {10.1109/RT.2007.4342598},
isbn = {9781424416295},
keywords = {I.3.6 [computer graphics]: Methodology and techniq},
title = {{Realtime ray tracing on GPU with BVH-based packet traversal}},
year = {2007}
}
@article{Bentley1975,
abstract = {This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given. {\textcopyright} 1975, ACM. All rights reserved.},
author = {Bentley, Jon Louis},
doi = {10.1145/361002.361007},
issn = {15577317},
journal = {Communications of the ACM},
keywords = {associative retrieval,attribute,binary search trees,binary tree insertion,information retrieval system,intersection queries,key,nearest neighbor queries,partial match queries},
pages = {509--517},
title = {{Multidimensional Binary Search Trees Used for Associative Searching}},
year = {1975}
}
@incollection{Jensen1996,
abstract = {This paper presents a two pass global illumination method based on the concept of photon maps. It represents a significant improvement of a previously described approach both with respect to speed, accuracy and versatility. In the first pass two photon maps are created by emitting packets of energy (photons) from the light sources and storing these as they hit surfaces within the scene. We use one high resolution caustics photon map to render caustics that are visualized directly and one low resolution photon map that is used during the rendering step. The scene is rendered using a distribution ray tracing algorithm optimized by using the in- formation in the photon maps. Shadow photons are used to render shadows more efficiently and the directional information in the photon map is used to generate optimized sampling directions and to limit the recursion in the distribution ray tracer by providing an estimate of the radiance on all surfaces with the exception of specular and highly glossy surfaces. The results presented demonstrate global illumination in scenes containing pro- cedural objects and surfaces with diffuse and glossy reflection models. The imple- mentation is also compared with the Radiance program.},
author = {Jensen, Henrik Wann},
booktitle = {Rendering Techniques '96},
pages = {21--30},
publisher = {Springer Vienna},
title = {{Global Illumination using Photon Maps}},
year = {1996}
}
@inproceedings{Hunt2008,
abstract = {The key to efficient ray tracing is the use of effective acceleration data structures. Traditionally, acceleration structures have been constructed under the assumption that rays approach from any direction with equal probability. However, we observe that for any particular frame the system has significant knowledge about the rays, especially eye rays and hard/soft shadow rays. In this paper we demonstrate that by using this information in conjunction with an appropriate acceleration structure - a set of one or more perspective grids - that ray tracing performance can be significantly improved over prior approaches. This acceleration structure can easily be rebuilt per frame, and provides significantly improved performance for rays originating at or near particular points such as the eye point and the light source(s), without sacrificing the ability to trace arbitrary rays. We demonstrate true real-time frame rates on a game-like scene rendered on an eight-core desktop PC at 1920times1200 resolution for primary visibility, and hard shadows, along with lower frame rates for Monte Carlo soft shadows. In particular, we demonstrate the fastest hard shadow ray-tracing results that we are aware of. We argue that the perspective grid acceleration structure provides insight into why the Z buffer algorithm is faster than traditional ray tracing and shows there is a useful continuum of visibility algorithms between the two traditional approaches.},
author = {Hunt, Warren and Mark, William R.},
booktitle = {RT'08 - IEEE/EG Symposium on Interactive Ray Tracing 2008, Proceedings},
keywords = {I.3.7 [computing methodologies]: computer graphics},
pages = {3--10},
title = {{Ray-specialized acceleration structures for ray tracing}},
year = {2008}
}
@book{Ericson2004,
abstract = {Today's sophisticated 3D games, virtual reality applications, and physical simulators involve rich graphical environments of millions of polygons. In these worlds, hundreds, perhaps even thousands of detailed animated objects may be interacting not only with these complex environments but also amongst themselves. With a typical update rate of 60 frames per second, a minimal amount of time is available for determining the intersection status of all objects in the world at a given time in order to maintain a believable simulation. Real-Time Collision Detection is a comprehensive, in-depth survey of the data structures and algorithms that make this possible. Taking a practical approach, the book discusses all the important components of an efficient real-time collision detection system. Topics covered include object representations, intersection tests, and distance queries, and the mathematics behind them: hierarchical and spatial partitioning methods, numerical and geometrical robustness issues, hardware acceleration methods, and advanced optimization for modern computer architectures. This book extends and broadens the discussion of collision detection in Collision Detection in Interactive 3D Environments.},
author = {Ericson, Christer},
booktitle = {Real-Time Collision Detection},
doi = {10.1201/b14581},
pages = {236--237},
title = {{Real-Time Collision Detection}},
year = {2004}
}
@book{ShirleyRTC,
author = {Shirley, Peter},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/Ray Tracing{\_} The Next Week.pdf:pdf},
keywords = {Path Tracing,Ray Tracing},
pages = {50},
publisher = {Peter Shirley},
title = {{Ray Tracing : The Next Week}},
url = {https://github.com/petershirley/raytracingthenextweek},
year = {2019}
}
@article{Karimi2010,
abstract = {CUDA and OpenCL are two different frameworks for GPU programming. OpenCL is an open standard that can be used to program CPUs, GPUs, and other devices from different vendors, while CUDA is specific to NVIDIA GPUs. Although OpenCL promises a portable language for GPU programming, its generality may entail a performance penalty. In this paper, we use complex, near-identical kernels from a Quantum Monte Carlo application to compare the performance of CUDA and OpenCL. We show that when using NVIDIA compiler tools, converting a CUDA kernel to an OpenCL kernel involves minimal modifications. Making such a kernel compile with ATI's build tools involves more modifications. Our performance tests measure and compare data transfer times to and from the GPU, kernel execution times, and end-to-end application execution times for both CUDA and OpenCL.},
author = {Karimi, Kamran and Dickson, Neil G. and Hamze, Firas},
file = {:home/jordi/Documents/Universidad/Computacio/TFG/Documents/cuda-ocl-kdh.pdf:pdf},
journal = {Computing Research Repository - CORR},
pages = {10},
title = {{A Performance Comparison of CUDA and OpenCL}},
year = {2010}
}
@inproceedings{Cassagnabere2004,
author = {Cassagnab{\`{e}}re, Christophe and Rousselle, Fran{\c{c}}ois and Renaud, Christophe},
booktitle = {Proceedings GRAPHITE 2004 - 2nd International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia},
keywords = {AR350,Global illumination,Hardware implementation,Path tracing,RenderMan},
pages = {23----29},
title = {{Path tracing using the AR350 processor}},
year = {2004}
}
@inproceedings{Moller2005,
abstract = {We present a clean algorithm for determining whether a ray intersects a triangle. The algorithm translates the origin of the ray and then changes the base of that vector which yields a vector (t u v)T, where t is the distance to the plane in which the triangle lies and (u, v) represents the coordinates inside the triangle. One advantage of this method is that the plane equation need not be computed on the fly nor be stored, which can amount to significant memory savings for triangle meshes. As we found our method to be comparable in speed to previous methods, we believe it is the fastest ray/triangle intersection routine for triangles which do not have precomputed plane equations.},
author = {M{\"{o}}ller, Tomas and Trumbore, Ben},
booktitle = {ACM SIGGRAPH 2005 Courses, SIGGRAPH 2005},
keywords = {Base transformation,Intersection,Ray tracing,Ray/triangle-intersection},
title = {{Fast, minimum storage ray/triangle intersection}},
year = {2005}
}
@inproceedings{Fang2011,
abstract = {This paper presents a comprehensive performance comparison between CUDA and OpenCL. We have selected 16 benchmarks ranging from synthetic applications to real-world ones. We make an extensive analysis of the performance gaps taking into account programming models, optimization strategies, architectural details, and underlying compilers. Our results show that, for most applications, CUDA performs at most 30{\%} better than OpenCL. We also show that this difference is due to unfair comparisons: in fact, OpenCL can achieve similar performance to CUDA under a fair comparison. Therefore, we define a fair comparison of the two types of applications, providing guidelines for more potential analyses. We also investigate OpenCL's portability by running the benchmarks on other prevailing platforms with minor modifications. Overall, we conclude that OpenCL's portability does not fundamentally affect its performance, and OpenCL can be a good alternative to CUDA. ? 2011 IEEE.},
author = {Fang, Jianbin and Varbanescu, Ana Lucia and Sips, Henk},
booktitle = {Proceedings of the International Conference on Parallel Processing},
keywords = {CUDA,OpenCL,Performance Comparison},
pages = {216----215},
title = {{A comprehensive performance comparison of CUDA and OpenCL}},
year = {2011}
}
@article{Fujimoto1986,
abstract = {In this article we propose algorithms that address the two basic problems encountered in generating continuous-tone images by ray tracing: Speed and aliasing. We examine previous approaches to the problem and then propose a scheme based on the coherency of an auxiliary data structure imposed on the original object domain. After investigating both simple spatial enumeration and a hybrid octree approach, we developed 3DDDA, a 3D line generator for efficient traversing of both structures. 3DDDA provides an order of magnitude improvement in processing speed compared to other known ray-tracing methods. Processing time is found to be virtually independent of the number of objects involved in the scene. For large numbers of objects, this method actully becomes faster than Scan Line methods. To remove jags from edges, a scheme for identifying edge orientation and distance from pixel center to true edge has been implemented. The time required for antialiasing depends on the total length of the edges encountered, but it is normally only a fractional addition to the time needed to produce the scene without antialiasing. {\textcopyright} 1986 IEEE},
author = {Fujimoto, Akira and Tanaka, Takayuki and Iwata, Kansei},
doi = {10.1109/MCG.1986.276715},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
pages = {16----26},
title = {{Arts: Accelerated Ray-Tracing System}},
year = {1986}
}
@inproceedings{Blinn1977,
abstract = {In the production of computer generated pictures of three dimensional objects, one stage of the calculation is the determination of the intensity of a given object once its visibility has been established. This is typically done by modelling the surface as a perfect diffuser, sometimes with a specular component added for the simulation of hilights. This paper presents a more accurate function for the generation of hilights which is based on some experimental measurements of how light reflects from real surfaces. It differs from previous models in that the intensity of the hilight changes with the direction of the light source. Also the position and shape of the hilights is somewhat different from that generated by simpler models. Finally, the hilight function generates different results when simulating metallic vs. nonmetallic surfaces. Many of the effects so generated are somewhat subtle and are apparent only during movie sequences. Some representative still frames from such movies are included.},
author = {Blinn, James F.},
booktitle = {Proceedings of the 4th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1977},
keywords = {Computer graphics,Graphic display,Hidden surface removal.,Shading},
title = {{Models of light reflection for computer synthesized pictures}},
year = {1977}
}
@article{Lafortune1993,
abstract = {In this paper we present a new Monte Carlo rendering algorithm that seamlessly integrates the ideas of},
author = {Lafortune, Eric P. and Willems, Yves D.},
journal = {Proceedings of Third International Conference on Computational Graphics and Visualization Techniques (Compugraphics '93)},
keywords = {illumination and photorealistic render-,rendering and visualisation global},
pages = {145----153},
title = {{Bi-Directional Path Tracing}},
year = {1993}
}
@article{Phong1975,
abstract = {The quality of computer generated images of three-dimensional scenes$\backslash$ndepends on the shading technique used to paint the objects on the$\backslash$ncathode-ray tube screen. The shading algorithm itself depends in$\backslash$npart on the method for modeling the object, which also determines$\backslash$nthe hidden surface algorithm. The various methods of object modeling,$\backslash$nshading, and hidden surface removal are thus strongly interconnected.$\backslash$nSeveral shading techniques corresponding to different methods of$\backslash$nobject modeling and the related hidden surface algorithms are presented$\backslash$nhere. Human visual perception and the fundamental laws of optics$\backslash$nare considered in the development of a shading rule that provides$\backslash$nbetter quality and increased realism in generated images.},
author = {Phong, Bui Tuong},
journal = {Communications of the ACM},
keywords = {computer graphics,graphic display,hidden surface removal,shading},
number = {6},
pages = {311----317},
title = {{Illumination for Computer Generated Pictures}},
volume = {18},
year = {1975}
}
@inproceedings{Karras2013,
abstract = {We propose a new massively parallel algorithm for constructing high-quality bounding volume hierarchies (BVHs) for ray tracing. The algorithm is based on modifying an existing BVH to improve its quality, and executes in linear time at a rate of almost 40M tri- angles/sec on NVIDIA GTX Titan. We also propose an improved approach for parallel splitting of triangles prior to tree construc- tion. Averaged over 20 test scenes, the resulting trees offer over 90{\%} of the ray tracing performance of the best offline construction method (SBVH), while previous fast GPU algorithms offer only about 50{\%}. Compared to state-of-the-art, our method offers a sig- nificant improvement in the majority of practical workloads that need to construct the BVH for each frame. On the average, it gives the best overall performance when tracing between 7 million and 60 billion rays per frame. This covers most interactive applications, product and architectural design, and even movie rendering.},
author = {Karras, Tero and Aila, Timo},
booktitle = {Proceedings - High-Performance Graphics 2013, HPG 2013},
keywords = {Bounding volume hierarchies,Ray tracing},
title = {{Fast parallel construction of high-quality bounding volume hierarchies}},
year = {2013}
}
